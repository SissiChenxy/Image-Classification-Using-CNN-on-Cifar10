{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR10_mnistMethod.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"y9NShTye0_eE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":71},"outputId":"9cbda79d-172c-4cd3-8be9-8f4da25894cb","executionInfo":{"status":"ok","timestamp":1524677435702,"user_tz":240,"elapsed":11614,"user":{"displayName":"Xinyun Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116701299885184002834"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":27,"outputs":[{"output_type":"stream","text":["WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"],"name":"stderr"},{"output_type":"stream","text":["··········\n"],"name":"stdout"}]},{"metadata":{"id":"J8SXQ7zn0-ly","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive -o nonempty"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NAzXZB3I0cAW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pickle\n","import numpy as np\n","import tensorflow as tf\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z-67SPor0cAp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x_train= None\n","\n","for i in range(5):\n","    xs=[]\n","    ys=[]\n","    f = open('drive/7390final/cifar_10/data_batch_' + str(i + 1), 'rb')\n","    datadict = pickle.load(f, encoding='latin1')\n","    f.close()\n","\n","    _X = datadict[\"data\"]\n","    _Y = datadict['labels']\n","            \n","    _X = _X.reshape(10000,3,32,32).transpose(0,2,3,1).astype(\"float32\")\n","    _Y = np.array(_Y)\n","\n","    xs.append(_X)\n","    ys.append(_Y)\n","    train_data = np.concatenate(xs)\n","    train_labels = np.concatenate(ys)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KWjG3mPL0cAt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yCX2eN5g0cAx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Test Data\n","f = open('drive/7390final/cifar_10/test_batch', 'rb')\n","datadict = pickle.load(f, encoding='latin1')\n","f.close()\n","\n","x_test = datadict[\"data\"]\n","y_test = np.array(datadict['labels'])\n","\n","x_test = np.array(x_test, dtype='float32')\n","test_data = x_test\n","test_labels = y_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JaeOnFNR0cA0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W1Xxp7Gu0cA4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def cnn_model_fn(features, labels, mode):\n","    \"\"\"Model function for CNN.\"\"\"\n","\n","    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n","    \n","    # Computes 32 features using a 5x5 filter \n","    # with ReLU activation.\n","    # Input Tensor Shape: [5, 32, 32, 3]\n","    # Output Tensor Shape: [5, 32, 32, 32]\n","    conv1 = tf.layers.conv2d(\n","        inputs=input_layer,\n","        filters=32,\n","        kernel_size=[5, 5],\n","        padding=\"same\",\n","        activation=tf.nn.relu)\n","\n","    \n","    # First max pooling layer with a 2x2 filter \n","    # and stride of 2\n","    # Input Tensor Shape: [5, 32, 32, 96]\n","    # Output Tensor Shape: [5, 16, 16, 96]\n","    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n","                     pool_size=[2, 2], strides=2)\n","\n","  \n","    # Computes 64 features using a 5x5 filter.\n","    # Padding is added to preserve width and height.\n","    # Input Tensor Shape: [5, 16, 16, 32]\n","    # Output Tensor Shape: [5, 16, 16, 64]\n","    conv2 = tf.layers.conv2d(\n","        inputs=pool1,\n","        filters=64,\n","        kernel_size=[5, 5],\n","        padding=\"same\",\n","        activation=tf.nn.relu)\n","\n","    # Pooling Layer #2\n","    # Second max pooling layer with a 2x2 filter \n","    # and stride of 2\n","    # Input Tensor Shape: [5, 16, 16, 64]\n","    # Output Tensor Shape: [5, 8, 8, 64]\n","    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n","                     pool_size=[2, 2], strides=2)\n","\n","    # Flatten tensor into a batch of vectors\n","    # Input Tensor Shape: [5, 8, 8, 64]\n","    # Output Tensor Shape: [5, 8 * 8 * 64]\n","    pool2_flat = tf.reshape(pool2, [-1, 8 * 8 * 64])\n","\n","    # Dense Layer\n","    # Densely connected layer with 1024 neurons\n","    # Input Tensor Shape: [batch_size, 8 * 8 * 64]\n","    # Output Tensor Shape: [batch_size, 1024]\n","    dense = tf.layers.dense(inputs=pool2_flat, \n","            units=1024, activation=tf.nn.relu)\n","\n","    # 0.6 probability that element will be kept\n","    dropout = tf.layers.dropout(\n","        inputs=dense, rate=0.4,\n","        training=mode == tf.estimator.ModeKeys.TRAIN)\n","\n","    # Logits layer\n","    # Input Tensor Shape: [batch_size, 1024]\n","    # Output Tensor Shape: [batch_size, 10]\n","    logits = tf.layers.dense(inputs=dropout, units=10)\n","\n","    predictions = {\n","        # Generate predictions (for PREDICT and EVAL mode)\n","        \"classes\": tf.argmax(input=logits, axis=1),\n","        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n","        # `logging_hook`.\n","        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n","    }\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n","\n","    # Calculate Loss (for both TRAIN and EVAL modes)\n","    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","\n","    # Configure the Training Op (for TRAIN mode)\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n","        train_op = optimizer.minimize(\n","            loss=loss,\n","            global_step=tf.train.get_global_step())\n","        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n","\n","    # Add evaluation metrics (for EVAL mode)\n","    eval_metric_ops = {\n","        \"accuracy\": tf.metrics.accuracy(\n","            labels=labels, predictions=predictions[\"classes\"])}\n","    return tf.estimator.EstimatorSpec(\n","        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n","\n","\n","def main(unused_argv):\n","\n","    # Create the Estimator\n","    mnist_classifier = tf.estimator.Estimator(\n","        model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n","\n","    # Set up logging for predictions\n","    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n","    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n","    logging_hook = tf.train.LoggingTensorHook(\n","        tensors=tensors_to_log, every_n_iter=50)\n","\n","    # Train the model\n","    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","        x={\"x\":train_data},\n","        y=train_labels,\n","        batch_size=128,\n","        num_epochs=None,\n","        shuffle=True)\n","    mnist_classifier.train(\n","        input_fn=train_input_fn,\n","        steps=20000,\n","        hooks=[logging_hook])\n","\n","    # Evaluate the model and print results\n","    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n","        x={\"x\":test_data},\n","        y=test_labels,\n","        num_epochs=1,\n","        shuffle=False)\n","    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n","    print(eval_results)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zTrt66GH0cA8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["if __name__ == \"__main__\":\n","    tf.app.run()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hxQYAQ2J0cBC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}